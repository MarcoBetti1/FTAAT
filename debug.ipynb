{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d927b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEBUGGING\n",
    "def grade_test(single_token_vocab, num_facts=5, k=3): \n",
    "    \"\"\"\n",
    "    Generates a single test case,\n",
    "    queries GPT for a response, and grades the response.\n",
    "    Prints the results to the console.\n",
    "    Args:\n",
    "        single_token_vocab (list): List of single-token vocabulary.\n",
    "        num_facts (int): Number of facts to generate.\n",
    "        k (int): Number of tokens per key-value pair.\n",
    "    \"\"\"\n",
    "    facts_list, key_value_dict = generate_facts_k_tokens(num_facts, k, single_token_vocab)\n",
    "    prompt, question_keys_in_order = build_prompt_for_all_keys(facts_list)\n",
    "    answer = query_gpt(prompt, model=MODEL_NAME, temperature=0.0)\n",
    "    (response_seqs,correct_response_seqs), major_fromat_flaw, expected_token_count, response_token_count = grade_response(answer,question_keys_in_order=question_keys_in_order,key_value_dict=key_value_dict, num_facts=num_facts,k=k)\n",
    "    # Print Results\n",
    "    print(\"=== Prompt===\\n\")\n",
    "    print(prompt)\n",
    "    print(\"\\n=== Response ===\")\n",
    "    print(answer)\n",
    "    print(\"\\n=== Correct ===\")\n",
    "    correct_response_text = \"\\n\".join(key_value_dict[key] for key in question_keys_in_order)\n",
    "    print(correct_response_text)\n",
    "    print(\"\\n=== Accuracy ===\")\n",
    "    print(f\"Sequence Accuracy: {response_seqs:.2f}\")\n",
    "    print(f\"Token Accuracy: {correct_response_seqs:.2f}\")\n",
    "    print(f\"Major Format Flaw: {major_fromat_flaw}\")\n",
    "# Uncomment to Run the test\n",
    "#grade_test(single_token_vocab=single_token_vocab, num_facts=5, k=3)\n",
    "\n",
    "def example_prompt_and_response(single_token_vocab,num_facts=5, k=3): # For Debugging/testing\n",
    "    \"\"\"\n",
    "    Example prompt and response using the given single-token vocabulary.\n",
    "    Prints results to the console.\n",
    "    Args:\n",
    "        single_token_vocab (list): List of single-token vocabulary.\n",
    "        num_facts (int): Number of facts to generate.\n",
    "        k (int): Number of tokens per key-value pair.\n",
    "    \"\"\"\n",
    "    facts_list, key_value_dict = generate_facts_k_tokens(num_facts, k, single_token_vocab) # Generate facts\n",
    "\n",
    "    prompt, question_keys_in_order = build_prompt_for_all_keys(facts_list) # Build prompt  \n",
    "\n",
    "    print(\"=== Prompt===\\n\")\n",
    "    print(prompt)\n",
    "\n",
    "    print(\"\\n=== correct ===\")\n",
    "    for key in question_keys_in_order: # Print the correct answers in order\n",
    "        print(f\"{key_value_dict[key]}\")\n",
    "\n",
    "    answer = query_gpt(prompt, model=MODEL_NAME, temperature=0.0) # Query GPT\n",
    "    print(\"\\n=== GPT RESPONSE ===\")\n",
    "    print(answer)\n",
    "\n",
    "### UNCOMMENT TO RUN EXAMPLE PROMPT AND RESPONSE\n",
    "#example_prompt_and_response(single_token_vocab=single_token_vocab, num_facts=5, k=3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
